#!/bin/bash

# Xå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿å®Œæ•´ç‰ˆ
echo "ğŸ¦ æ­£åœ¨è·å–Xå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿å®Œæ•´æ•°æ®..."

# æ£€æŸ¥birdå‘½ä»¤æ˜¯å¦å­˜åœ¨
if ! command -v bird &> /dev/null; then
    echo "âŒ Error: bird CLI not found"
    exit 1
fi

# ä½¿ç”¨birdè·å–home timeline (For You feed)ï¼Œé™åˆ¶ä¸º100æ¡
echo "Fetching latest 100 posts from your For You feed (x.com/home)..."
POSTS_JSON=$(bird --auth-token a5dae1d338d51cccf62b766e37ad49e825003d24 --ct0 13bcad10ed93b032a4be627787f0741263201b7c6f45b7af60fd2b3ade9b7a4f20f31acb63a4ef7f9a44ae9da38a405a12d449eea853d405ae2766b23fdee46890a3be9e1c023a1bbd0a56c8f48cb382 home --count 100 --json 2>/dev/null)

if [ -z "$POSTS_JSON" ] || [ "$POSTS_JSON" = "" ] || [ "$POSTS_JSON" = "null" ]; then
    echo "âš ï¸ Warning: Could not fetch data using bird CLI"
    exit 1
fi

# å°†JSONæ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
TEMP_JSON_FILE=$(mktemp)
echo "$POSTS_JSON" > "$TEMP_JSON_FILE"

# ä½¿ç”¨Pythonå¤„ç†æ•°æ®å¹¶ç”Ÿæˆå®Œæ•´æ—¶é—´çº¿
python3 << EOF
import json
import re
from datetime import datetime

# ä»ä¸´æ—¶æ–‡ä»¶è¯»å–JSONæ•°æ®
with open('$TEMP_JSON_FILE', 'r', encoding='utf-8') as f:
    posts = json.load(f)

def extract_content_summary(text):
    """æå–æ¨æ–‡çš„æ ¸å¿ƒå†…å®¹å¹¶ç”Ÿæˆä¸­æ–‡ç»¼è¿°"""
    # ç§»é™¤URLé“¾æ¥
    text_clean = re.sub(r'https?://\S+', '', text)
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text_clean = ' '.join(text_clean.split())
    
    # å¦‚æœæ–‡æœ¬è¾ƒçŸ­ï¼Œç›´æ¥è¿”å›
    if len(text_clean) <= 100:
        return text_clean
    
    # å¦åˆ™æˆªå–å‰100ä¸ªå­—ç¬¦ä½œä¸ºç»¼è¿°
    summary = text_clean[:100].strip()
    
    # å¦‚æœåŸå§‹æ–‡æœ¬è¶…è¿‡100å­—ç¬¦ï¼Œæ·»åŠ çœç•¥å·
    if len(text_clean) > 100:
        summary += "..."
    
    return summary

# è¾“å‡ºæ ¼å¼åŒ–çš„å®Œæ•´æ—¶é—´çº¿ç®€æŠ¥
print('### ğŸ¦ Xå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿')
print(f'**æ—¥æœŸï¼š** {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}')
print(f'**æ€»è®¡ï¼š** {len(posts)} æ¡æœ€æ–°æ¨æ–‡')
print()

print('#### ğŸ“° æœ€æ–°æ¨æ–‡åˆ—è¡¨ï¼ˆæ¥è‡ªx.com/homeï¼‰')
print()

# æŒ‰æ—¶é—´é¡ºåºè¾“å‡ºæ‰€æœ‰æ¨æ–‡
for i, post in enumerate(posts, 1):
    text = post['text']
    like_count = post.get('likeCount', post.get('like_count', 0))
    retweet_count = post.get('retweetCount', post.get('retweet_count', 0))
    reply_count = post.get('replyCount', post.get('reply_count', 0))
    author = post.get('author', {}).get('username', 'unknown')
    created_at = post.get('createdAt', 'Unknown')
    url = f"https://x.com/{author}/status/{post['id']}" if 'id' in post and 'author' in post else '#'
    
    summary = extract_content_summary(text)
    
    print(f'**{i:2d}. @{author}**')
    print(f'**æ—¶é—´ï¼š** {created_at}')
    print(f'**äº’åŠ¨ï¼š** {like_count:,}èµ {retweet_count:,}è½¬ {reply_count:,}è¯„')
    print(f'**é“¾æ¥ï¼š** {url}')
    print(f'**å†…å®¹ï¼š** {summary}')
    print()

print(f'---')
print(f'*æ•°æ®æ¥æºï¼šXå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿ | åˆ†ææ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*')

# ä¿å­˜å®Œæ•´æŠ¥å‘Š
report_file = f'/home/chengzh/clawd/skills/x-platform-brief/full_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
with open(report_file, 'w', encoding='utf-8') as f:
    f.write('# Xå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿å®Œæ•´ç‰ˆ\\n')
    f.write(f'{datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")} å®Œæ•´æ—¶é—´çº¿\\n')
    f.write('\\n')
    f.write(f'### ğŸ¦ Xå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿\\n')
    f.write(f'**æ—¥æœŸï¼š** {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}\\n')
    f.write(f'**æ€»è®¡ï¼š** {len(posts)} æ¡æœ€æ–°æ¨æ–‡\\n')
    f.write('\\n')
    f.write('#### ğŸ“° æœ€æ–°æ¨æ–‡åˆ—è¡¨ï¼ˆæ¥è‡ªx.com/homeï¼‰\\n')
    f.write('\\n')
    
    for i, post in enumerate(posts, 1):
        text = post['text']
        like_count = post.get('likeCount', post.get('like_count', 0))
        retweet_count = post.get('retweetCount', post.get('retweet_count', 0))
        reply_count = post.get('replyCount', post.get('reply_count', 0))
        author = post.get('author', {}).get('username', 'unknown')
        created_at = post.get('createdAt', 'Unknown')
        url = f"https://x.com/{author}/status/{post['id']}" if 'id' in post and 'author' in post else '#'
        
        summary = extract_content_summary(text)
        
        f.write(f'**{i:2d}. @{author}**\\n')
        f.write(f'**æ—¶é—´ï¼š** {created_at}\\n')
        f.write(f'**äº’åŠ¨ï¼š** {like_count:,}èµ {retweet_count:,}è½¬ {reply_count:,}è¯„\\n')
        f.write(f'**é“¾æ¥ï¼š** {url}\\n')
        f.write(f'**å†…å®¹ï¼š** {summary}\\n')
        f.write('\\n')

    f.write('---\\n')
    f.write(f'*æ•°æ®æ¥æºï¼šXå¹³å°ä¸ªäººFor Youæ—¶é—´çº¿ | åˆ†ææ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\\n')

print(f'\\nğŸ’¾ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}')
EOF

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm "$TEMP_JSON_FILE"